{
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "collapsed": false
      },
      "execution_count": null,
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n# Gaussian KDE and Extents\n\n\nSmooth marginalised distributions with a Gaussian KDE, and pick custom extents.\n\n\nNote that invoking the KDE on large data sets will significantly increase rendering time.\nAlso note that you can only invoke KDE on chains without varying weights. This limitation will\nbe lifted as soon as statsmodel, scipy or scikit-learn add a weighted Gaussian KDE.\n\nAlso note that if you pass a floating point number to bins, it multiplies the default bin size\n(which is a function of number of steps in the chain) by that amount. If you give it an integer,\nit will use that many bins.\n\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "collapsed": false
      },
      "execution_count": null,
      "source": [
        "import numpy as np\nfrom chainconsumer import ChainConsumer\n\nif __name__ == \"__main__\":\n    data = np.random.multivariate_normal([0.0, 4.0], [[1.0, 0.7], [0.7, 1.5]], size=50000)\n\n    c = ChainConsumer()\n    c.add_chain(data)\n    c.configure_general(bins=0.9, kde=True)\n    c.plot(extents=[(-2, 4), (0, 10)])"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "version": "3.5.2",
      "nbconvert_exporter": "python",
      "file_extension": ".py",
      "name": "python",
      "pygments_lexer": "ipython3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3",
      "language": "python"
    }
  }
}